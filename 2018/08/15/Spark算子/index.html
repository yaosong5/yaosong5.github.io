<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="纵浪大化中，不喜亦不悲"><title>Spark算子案例 | 钢铁锅</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/8.0.0/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/3.3.1/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">Spark算子案例</h1><a id="logo" href="/.">钢铁锅</a><p class="description">应尽便须尽，无复独多虑</p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">Spark算子案例</h1><div class="post-meta">Aug 15, 2018<span> | </span><span class="category"><a href="/categories/大数据/">大数据</a></span></div><div class="clear"><div class="toc-article" id="toc"><div class="toc-title">文章目录</div><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#HelloWord？WorldCount"><span class="toc-number">1.</span> <span class="toc-text">HelloWord？WorldCount</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#mapPartitions"><span class="toc-number">1.1.</span> <span class="toc-text">mapPartitions</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#mapPartitionsWithIndex"><span class="toc-number">1.2.</span> <span class="toc-text">mapPartitionsWithIndex</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#aggregate-action"><span class="toc-number">1.3.</span> <span class="toc-text">aggregate (action)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#aggregateByKey"><span class="toc-number">1.4.</span> <span class="toc-text">aggregateByKey</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#combineByKey"><span class="toc-number">1.5.</span> <span class="toc-text">combineByKey</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#reduceByKey"><span class="toc-number">1.6.</span> <span class="toc-text">reduceByKey</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#groupByKey"><span class="toc-number">1.7.</span> <span class="toc-text">groupByKey</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#checkpoint"><span class="toc-number">1.8.</span> <span class="toc-text">checkpoint</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#coalesce-repartition"><span class="toc-number">1.9.</span> <span class="toc-text">coalesce, repartition</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#collectAsMap"><span class="toc-number">1.10.</span> <span class="toc-text">collectAsMap</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#countByKey"><span class="toc-number">1.11.</span> <span class="toc-text">countByKey</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#countByValue"><span class="toc-number">1.12.</span> <span class="toc-text">countByValue</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#filterByRange"><span class="toc-number">1.13.</span> <span class="toc-text">filterByRange</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#flatMapValues"><span class="toc-number">1.14.</span> <span class="toc-text">flatMapValues</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#foldByKey"><span class="toc-number">1.15.</span> <span class="toc-text">foldByKey</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#foreach"><span class="toc-number">1.16.</span> <span class="toc-text">foreach</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#foreachPartition"><span class="toc-number">1.17.</span> <span class="toc-text">foreachPartition</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#keyBy"><span class="toc-number">1.18.</span> <span class="toc-text">keyBy</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#keys-values"><span class="toc-number">1.19.</span> <span class="toc-text">keys values</span></a></li></ol></li></ol></div></div><div class="post-content"><p>[TOC]</p>
<h1 id="HelloWord？WorldCount"><a href="#HelloWord？WorldCount" class="headerlink" title="HelloWord？WorldCount"></a>HelloWord？WorldCount</h1><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sc.textfile(<span class="string">"hdfs://master:9000/wc"</span>).flatMap(_.split(<span class="string">"分隔符"</span>)).map((_,<span class="number">1</span>)).reduceByKey(_+_).saveAsTextFile(<span class="string">"hdfs://master:9000/wcResult"</span>)</span><br></pre></td></tr></table></figure>
<p>数据最开始在Driver，计算的时候数据会流入worker<br>当rdd形成过程中，worker的分区中只是预留了存放数据的位置，只有当action触发的时候，worker的分区中才会存在数据</p>
<p>Spark的运算都是通过算子进行RDD的转换及运算，那我们对算子进行简单熟悉<a href="http://homepage.cs.latrobe.edu.au/zhe/ZhenHeSparkRDDAPIExamples.html" target="_blank" rel="noopener">参考RDD算子实例</a></p>
<a id="more"></a>
<p>reduceByKey先进行一下combineer 移动计算</p>
<p>groupByKey不好</p>
<p>reduceByKey会在局部先进行一下求和</p>
<p>groupByKey是会将所有的数据放在一个大集合里面，然后再求和 ，会消耗更多的网络带宽，不符合计算本地化</p>
<p>一下一些RDD是给予rdd1来操作的</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> rdd1 = sc.parallelize(<span class="type">List</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>), <span class="number">2</span>)</span><br></pre></td></tr></table></figure>
<h2 id="mapPartitions"><a href="#mapPartitions" class="headerlink" title="mapPartitions"></a>mapPartitions</h2><p>map 是对 rdd 中的每一个元素进行操作，而 mapPartitions(foreachPartition) 则是对 rdd 中的每个分区的迭代器进行操作。如果在 map 过程中需要频繁创建额外的对象 (例如将 rdd 中的数据通过 jdbc 写入数据库, map 需要为每个元素创建一个链接而 mapPartition 为每个 partition 创建一个链接), 则 mapPartitions 效率比 map 高的多。</p>
<p>SparkSql 或 DataFrame 默认会对程序进行 mapPartition 的优化。</p>
<h2 id="mapPartitionsWithIndex"><a href="#mapPartitionsWithIndex" class="headerlink" title="mapPartitionsWithIndex"></a>mapPartitionsWithIndex</h2><p>mapPartitionWithIndex与mapPartition类似，只是会带上分区的序号</p>
<p>把每个partition中的<strong>分区号和对应的值</strong>拿出来, 源码中方法的形式：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> func(index,<span class="type">Int</span>,iter:<span class="type">Interator</span>[(<span class="type">Int</span>)]):<span class="type">Interator</span>[<span class="type">String</span>] = &#123;</span><br><span class="line">iter.toList.map(x =&gt; <span class="string">"[partID:"</span> +  index + <span class="string">", val: "</span> + x + <span class="string">"]"</span>).iterator</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>会转换成函数<br>函数的形式</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> func = (index: <span class="type">Int</span>, iter: <span class="type">Iterator</span>[(<span class="type">Int</span>)]) =&gt; &#123;</span><br><span class="line">  iter.toList.map(x =&gt; <span class="string">"[partID:"</span> +  index + <span class="string">", val: "</span> + x + <span class="string">"]"</span>).iterator</span><br><span class="line">&#125;</span><br><span class="line">rdd1.mapPartitionsWithIndex(func).collect</span><br></pre></td></tr></table></figure>
<p><img src="https://ws3.sinaimg.cn/large/006tNbRwgy1fucjpo4afaj31ik056whp.jpg" alt=""></p>
<h2 id="aggregate-action"><a href="#aggregate-action" class="headerlink" title="aggregate (action)"></a>aggregate (action)</h2><p>aggregate是一个action操作</p>
<p>源码定义</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">aggregate</span></span>[<span class="type">U</span>](zeroValue: <span class="type">U</span>)(seqOp: (<span class="type">U</span>, <span class="type">T</span>) ⇒ <span class="type">U</span>, combOp: (<span class="type">U</span>, <span class="type">U</span>) ⇒ <span class="type">U</span>)(<span class="keyword">implicit</span> arg0: <span class="type">ClassTag</span>[<span class="type">U</span>]): <span class="type">U</span></span><br></pre></td></tr></table></figure>
<p>eqOp 操作会聚合各分区中的元素，然后 combOp 操作把所有分区的聚合结果再次聚合，两个操作的初始值都是 zeroValue.   seqOp 的操作是遍历分区中的所有元素 (T)，第一个 T 跟 zeroValue 做操作，结果再作为与第二个 T 做操作的 zeroValue，直到遍历完整个分区。combOp 操作是把各分区聚合的结果，再聚合。aggregate 函数返回一个跟 RDD 不同类型的值。因此，需要一个操作 seqOp 来把分区中的元素 T 合并成一个 U，另外一个操作 combOp 把所有 U 聚合。</p>
<p>参考<a href="https://blog.csdn.net/qingyang0320/article/details/51603243" target="_blank" rel="noopener">理解 Spark RDD 中的 aggregate 函数</a></p>
<p>第一个参数：初始值（在进行操作的时候，会默认带入该值进行）<br>第二个参数:   是两个函数[每个函数都是2个参数(第一个函数:先对各个分区进行合并, 第二个函数:对各个分区合并后的结果再进行合并)] </p>
<p>最后得到返回值</p>
<blockquote>
<p>rdd1为上面的rdd1分区函数的结果</p>
</blockquote>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rdd1.aggregate(<span class="number">0</span>)(_+_, _+_)</span><br></pre></td></tr></table></figure>
<p><strong>0 + (0+1+2+3+4 + 0+5+6+7+8+9)</strong></p>
<p><img src="https://ws4.sinaimg.cn/large/006tNbRwgy1fuck6fl2chj30kg02ut96.jpg" alt=""></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rdd1.aggregate(<span class="number">7</span>)(_+_, _+_)</span><br></pre></td></tr></table></figure>
<p><strong>7 + (7+1+2+3+4 + 7+5+6+7+8+9)</strong></p>
<p><img src="https://ws4.sinaimg.cn/large/006tNbRwgy1fuck87fxhij30ju02gt92.jpg" alt=""></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rdd1.aggregate(<span class="number">0</span>)(math.max(_, _), _ + _)</span><br></pre></td></tr></table></figure>
<p><img src="https://ws4.sinaimg.cn/large/006tNbRwgy1fuck95wu88j30qo02o74x.jpg" alt=""></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rdd1.aggregate(<span class="number">5</span>)(math.max(_, _), _ + _)</span><br></pre></td></tr></table></figure>
<p><strong>5和1比, 得5再和234比得5 –&gt; 5和6789比,得9 –&gt; 5 + (5+9)</strong></p>
<p><img src="https://ws4.sinaimg.cn/large/006tNbRwgy1fucouprhcjj30s402yjs5.jpg" alt=""></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> rdd2 = sc.parallelize(<span class="type">List</span>(<span class="string">"q"</span>,<span class="string">"w"</span>,<span class="string">"e"</span>,<span class="string">"r"</span>,<span class="string">"t"</span>,<span class="string">"y"</span>,<span class="string">"u"</span>,<span class="string">"i"</span>,<span class="string">"o"</span>,<span class="string">"p"</span>),<span class="number">2</span>)</span><br></pre></td></tr></table></figure>
<p>可以用更加直接的方式验证操作</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">func2</span></span>(index: <span class="type">Int</span>, iter: <span class="type">Iterator</span>[(<span class="type">String</span>)]) : <span class="type">Iterator</span>[<span class="type">String</span>] = &#123;</span><br><span class="line">  iter.toList.map(x =&gt; <span class="string">"[partID:"</span> +  index + <span class="string">", val: "</span> + x + <span class="string">"]"</span>).iterator</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">rdd2.aggregate(<span class="string">""</span>)(_ + _, _ + _)</span><br><span class="line">rdd2.aggregate(<span class="string">"="</span>)(_ + _, _ + _)</span><br><span class="line">rdd2.aggregate(<span class="string">"|"</span>)(_ + _, _ + _)</span><br></pre></td></tr></table></figure>
<p><img src="https://ws1.sinaimg.cn/large/006tNbRwgy1fucpd6axxej30os034wf7.jpg" alt=""></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> rdd3 = sc.parallelize(<span class="type">List</span>(<span class="string">"qazqqw7"</span>,<span class="string">"jishhrwe9"</span>,<span class="string">"sdfwezsddf12"</span>,<span class="string">"12esdww8"</span>),<span class="number">2</span>)</span><br><span class="line">rdd3.aggregate(<span class="string">""</span>)((x,y) =&gt; math.max(x.length, y.length).toString, (x,y) =&gt; x + y)</span><br></pre></td></tr></table></figure>
<p><img src="https://ws3.sinaimg.cn/large/006tNbRwgy1fucpvxoentj31gw03276d.jpg" alt=""></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> rdd4 = sc.parallelize(<span class="type">List</span>(<span class="string">"qazqqw7"</span>,<span class="string">"jishhrwe9"</span>,<span class="string">"sdfwezsddf12"</span>,<span class="string">""</span>),<span class="number">2</span>)</span><br><span class="line">rdd4.aggregate(<span class="string">""</span>)((x,y) =&gt; math.min(x.length, y.length).toString, (x,y) =&gt; x + y)</span><br></pre></td></tr></table></figure>
<p><img src="https://ws1.sinaimg.cn/large/006tNbRwgy1fucpwdi27nj31g8032abq.jpg" alt=""></p>
<h2 id="aggregateByKey"><a href="#aggregateByKey" class="headerlink" title="aggregateByKey"></a>aggregateByKey</h2><p>对每个分区进行计算</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> pairRDD = sc.parallelize(<span class="type">List</span>( (<span class="string">"a"</span>,<span class="number">1</span>), (<span class="string">"a"</span>, <span class="number">12</span>), (<span class="string">"b"</span>, <span class="number">4</span>),(<span class="string">"c"</span>, <span class="number">17</span>), (<span class="string">"c"</span>, <span class="number">12</span>), (<span class="string">"b"</span>, <span class="number">2</span>)), <span class="number">2</span>)</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">func2</span></span>(index: <span class="type">Int</span>, iter: <span class="type">Iterator</span>[(<span class="type">String</span>, <span class="type">Int</span>)]) : <span class="type">Iterator</span>[<span class="type">String</span>] = &#123;</span><br><span class="line">  iter.toList.map(x =&gt; <span class="string">"[partID:"</span> +  index + <span class="string">", val: "</span> + x + <span class="string">"]"</span>).iterator</span><br><span class="line">&#125;</span><br><span class="line">pairRDD.mapPartitionsWithIndex(func2).collect</span><br></pre></td></tr></table></figure>
<h2 id="combineByKey"><a href="#combineByKey" class="headerlink" title="combineByKey"></a>combineByKey</h2><p>reduceByKey aggregateByKey底层都是依赖的combineByKey，combineByKey比较底层的算子<br>和reduceByKey是相同的效果</p>
<p><strong>combineByKey有三个参数</strong></p>
<p>第一个参数x: <strong>原封不动取出来</strong>  第二个参数:<strong>是函数, 局部运算</strong>, 第三个:是函数, <strong>对局部运算后的结果再做运算</strong></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> rdd4 = sc.parallelize(<span class="type">List</span>(<span class="string">"a"</span>,<span class="string">"b"</span>,<span class="string">"c"</span>,<span class="string">"d"</span>,<span class="string">"e"</span>,<span class="string">"f"</span>,<span class="string">"g"</span>,<span class="string">"h"</span>,<span class="string">"i"</span>),<span class="number">2</span>)</span><br><span class="line"><span class="keyword">val</span> rdd5 = sc.parallelize(<span class="type">List</span>(<span class="number">1</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>),<span class="number">2</span>)</span><br><span class="line"><span class="keyword">val</span> rdd6 = rdd5.zip(rdd4)</span><br><span class="line"><span class="keyword">val</span> rdd7 = rdd6.combineByKey(<span class="type">List</span>(_),(x:<span class="type">List</span>[<span class="type">String</span>],y:<span class="type">String</span>)=&gt;x:+y,(m:<span class="type">List</span>[<span class="type">String</span>],n:<span class="type">List</span>[<span class="type">String</span>])=&gt;m ++ n)</span><br><span class="line">rdd7.collect</span><br></pre></td></tr></table></figure>
<h2 id="reduceByKey"><a href="#reduceByKey" class="headerlink" title="reduceByKey"></a>reduceByKey</h2><p>reduceByKey 用于对每个 key 对应的多个 value 进行 merge 操作，最重要的是它能够在本地先进行 merge 操作，并且 merge 操作可以通过函数自定义。</p>
<h2 id="groupByKey"><a href="#groupByKey" class="headerlink" title="groupByKey"></a>groupByKey</h2><p>groupByKey 也是对每个 key 进行操作，但只生成一个 sequence。不会再进行</p>
<p>需要特别注意 “Note” 中的话，它告诉我们：如果需要对 sequence 进行 aggregation 操作（注意，groupByKey 本身不能自定义操作函数），那么，选择 reduceByKey/aggregateByKey 更好。这是因为 groupByKey 不能自定义函数，我们需要先用 groupByKey 生成 RDD，然后才能对此 RDD 通过 map 进行自定义函数操作。</p>
<h2 id="checkpoint"><a href="#checkpoint" class="headerlink" title="checkpoint"></a>checkpoint</h2><p>将rdd内容持久化</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">sc.setCheckpointDir(<span class="string">"hdfs://master:9000/ck"</span>)</span><br><span class="line"><span class="keyword">val</span> rdd = sc.textFile(<span class="string">"hdfs://master:9000/wc"</span>).flatMap(_.split(<span class="string">" "</span>)).map((_, <span class="number">1</span>)).reduceByKey(_+_)</span><br><span class="line">rdd.checkpoint</span><br><span class="line">rdd.isCheckpointed</span><br><span class="line">rdd.count</span><br><span class="line">rdd.isCheckpointed</span><br><span class="line">rdd.getCheckpointFile</span><br></pre></td></tr></table></figure>
<h2 id="coalesce-repartition"><a href="#coalesce-repartition" class="headerlink" title="coalesce, repartition"></a>coalesce, repartition</h2><p>有时候需要重新设置 Rdd 的分区数量，比如 Rdd 的分区中，Rdd 分区比较多，但是每个 Rdd 的数据量比较小，需要设置一个比较合理的分区。或者需要把 Rdd 的分区数量调大。还有就是通过设置一个 Rdd 的分区来达到设置生成的文件的数量。</p>
<p>如果分区的数量发生激烈的变化，如设置 numPartitions = 1，这可能会造成运行计算的节点比你想象的要少，为了避免这个情况，可以设置 shuffle=true，</p>
<p>那么这会增加 shuffle 操作。</p>
<p>关于这个分区的激烈的变化情况，比如分区数量从父 Rdd 的几千个分区设置成几个，有可能会遇到这么一个错误。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">java.io.IOException: Unable to acquire 16777216 bytes of memory</span><br></pre></td></tr></table></figure>
<p>这个错误只要把 shuffle 设置成 true 即可解决。</p>
<p>当把父 Rdd 的分区数量增大时，比如 Rdd 的分区是 100，设置成 1000，如果 shuffle 为 false，并不会起作用。</p>
<p>这时候就需要设置 shuffle 为 true 了，那么 Rdd 将在 shuffle 之后返回一个 1000 个分区的 Rdd，数据分区方式默认是采用 hash partitioner。</p>
<p>最后来看看 repartition() 方法的源码：</p>
<p>coalesce() 方法的作用是返回指定一个新的指定分区的 Rdd。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> rdd1 = sc.parallelize(<span class="number">1</span> to <span class="number">10</span>, <span class="number">10</span>)</span><br><span class="line"><span class="keyword">val</span> rdd2 = rdd1.coalesce(<span class="number">2</span>, <span class="literal">false</span>)</span><br><span class="line">rdd2.partitions.length</span><br></pre></td></tr></table></figure>
<p><a href="https://www.cnblogs.com/fillPv/p/5392186.html" target="_blank" rel="noopener"></a></p>
<h2 id="collectAsMap"><a href="#collectAsMap" class="headerlink" title="collectAsMap"></a>collectAsMap</h2><p>将其他集合保存为map结构</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> rdd = sc.parallelize(<span class="type">List</span>((<span class="string">"a"</span>, <span class="number">1</span>), (<span class="string">"b"</span>, <span class="number">2</span>)))</span><br><span class="line">rdd.collectAsMap</span><br><span class="line">得到结果</span><br><span class="line"><span class="type">Map</span>(b -&gt; <span class="number">2</span>, a -&gt; <span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<h2 id="countByKey"><a href="#countByKey" class="headerlink" title="countByKey"></a>countByKey</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> rdd1 = sc.parallelize(<span class="type">List</span>((<span class="string">"a"</span>, <span class="number">1</span>), (<span class="string">"b"</span>, <span class="number">2</span>), (<span class="string">"b"</span>, <span class="number">2</span>), (<span class="string">"c"</span>, <span class="number">2</span>), (<span class="string">"c"</span>, <span class="number">1</span>)))</span><br><span class="line">rdd1.countByKey </span><br><span class="line">统计<span class="type">Key</span>出现的次数</span><br><span class="line">结果 <span class="type">Map</span>(b -&gt; <span class="number">2</span>, a -&gt; <span class="number">1</span>, c -&gt; <span class="number">2</span>)</span><br></pre></td></tr></table></figure>
<h2 id="countByValue"><a href="#countByValue" class="headerlink" title="countByValue"></a>countByValue</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> rdd1 = sc.parallelize(<span class="type">List</span>((<span class="string">"a"</span>, <span class="number">1</span>), (<span class="string">"b"</span>, <span class="number">2</span>), (<span class="string">"b"</span>, <span class="number">2</span>), (<span class="string">"c"</span>, <span class="number">2</span>), (<span class="string">"c"</span>, <span class="number">1</span>)))</span><br><span class="line">rdd1.countByValue</span><br><span class="line">结果 (将整个元组作为key)</span><br><span class="line"><span class="type">Map</span>((b,<span class="number">2</span>) -&gt; <span class="number">2</span>, (c,<span class="number">2</span>) -&gt; <span class="number">1</span>, (a,<span class="number">1</span>) -&gt; <span class="number">1</span>, (c,<span class="number">1</span>) -&gt; <span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<h2 id="filterByRange"><a href="#filterByRange" class="headerlink" title="filterByRange"></a>filterByRange</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> rdd1 = sc.parallelize(<span class="type">List</span>((<span class="string">"a"</span>, <span class="number">5</span>), (<span class="string">"b"</span>, <span class="number">3</span>), (<span class="string">"c"</span>, <span class="number">4</span>), (<span class="string">"d"</span>, <span class="number">2</span>), (<span class="string">"e"</span>, <span class="number">1</span>)))</span><br><span class="line"><span class="keyword">val</span> rdd2 = rdd1.filterByRange(<span class="string">"b"</span>, <span class="string">"d"</span>)</span><br><span class="line">rdd2.collect</span><br><span class="line"></span><br><span class="line"><span class="type">Array</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = <span class="type">Array</span>((b,<span class="number">3</span>), (c,<span class="number">4</span>), (d,<span class="number">2</span>))</span><br></pre></td></tr></table></figure>
<h2 id="flatMapValues"><a href="#flatMapValues" class="headerlink" title="flatMapValues"></a>flatMapValues</h2><p>压平</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> rdd3 = sc.parallelize(<span class="type">List</span>((<span class="string">"a"</span>, <span class="string">"1 2"</span>), (<span class="string">"b"</span>, <span class="string">"3 4"</span>)))</span><br><span class="line"><span class="keyword">val</span> rdd4 = rdd3.flatMapValues(_.split(<span class="string">" "</span>))</span><br><span class="line">rdd4.collect</span><br><span class="line"></span><br><span class="line"><span class="type">Array</span>[(<span class="type">String</span>, <span class="type">String</span>)] = <span class="type">Array</span>((a,<span class="number">1</span>), (a,<span class="number">2</span>), (b,<span class="number">3</span>), (b,<span class="number">4</span>))</span><br></pre></td></tr></table></figure>
<h2 id="foldByKey"><a href="#foldByKey" class="headerlink" title="foldByKey"></a>foldByKey</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> rdd1 = sc.parallelize(<span class="type">List</span>(<span class="string">"a22"</span>, <span class="string">"b232"</span>, <span class="string">"c"</span>, <span class="string">"d"</span>), <span class="number">2</span>)</span><br><span class="line"><span class="keyword">val</span> rdd2 = rdd1.map(x =&gt; (x.length, x))</span><br><span class="line">rdd2.collect</span><br><span class="line">结果： <span class="type">Array</span>[(<span class="type">Int</span>, <span class="type">String</span>)] = <span class="type">Array</span>((<span class="number">3</span>,a22), (<span class="number">4</span>,b232), (<span class="number">1</span>,c), (<span class="number">1</span>,d))</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> rdd3 = rdd2.foldByKey(<span class="string">""</span>)(_+_)</span><br><span class="line">rdd3.collect</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">结果：将相同key的元组合并在一起，</span><br><span class="line"><span class="type">Array</span>[(<span class="type">Int</span>, <span class="type">String</span>)] = <span class="type">Array</span>((<span class="number">4</span>,b232), (<span class="number">1</span>,cd), (<span class="number">3</span>,a22))</span><br></pre></td></tr></table></figure>
<h2 id="foreach"><a href="#foreach" class="headerlink" title="foreach"></a>foreach</h2><p>foreach是针对于每一个元素，<br>foreachPartition是针对每一个分区，<br>foreachPartition是写入数据库时，可以将在foreachPartition时获得一个数据库连接，通过map方法来将每个分区的全部元素写入到数据库</p>
<h2 id="foreachPartition"><a href="#foreachPartition" class="headerlink" title="foreachPartition"></a>foreachPartition</h2><p>3个分区</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> rdd1 = sc.parallelize(<span class="type">List</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>), <span class="number">3</span>)</span><br><span class="line">rdd1.foreachPartition(x =&gt; println(x.reduce(_ + _)))</span><br></pre></td></tr></table></figure>
<h2 id="keyBy"><a href="#keyBy" class="headerlink" title="keyBy"></a>keyBy</h2><p>以传入的参数做key</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> rdd1 = sc.parallelize(<span class="type">List</span>(<span class="string">"dog"</span>, <span class="string">"salmon"</span>, <span class="string">"salmon"</span>, <span class="string">"rat"</span>, <span class="string">"elephant"</span>), <span class="number">3</span>)</span><br><span class="line"><span class="keyword">val</span> rdd2 = rdd1.keyBy(_.length)</span><br><span class="line">rdd2.collect</span><br><span class="line">结果 <span class="type">Array</span>((<span class="number">3</span>,dog), (<span class="number">6</span>,salmon), (<span class="number">6</span>,salmon), (<span class="number">3</span>,rat), (<span class="number">8</span>,elephant))</span><br></pre></td></tr></table></figure>
<h2 id="keys-values"><a href="#keys-values" class="headerlink" title="keys values"></a>keys values</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> rdd1 = sc.parallelize(<span class="type">List</span>(<span class="string">"dog"</span>, <span class="string">"tiger"</span>, <span class="string">"lion"</span>, <span class="string">"cat"</span>, <span class="string">"panther"</span>, <span class="string">"eagle"</span>), <span class="number">2</span>)</span><br><span class="line"><span class="keyword">val</span> rdd2 = rdd1.map(x =&gt; (x.length, x))</span><br><span class="line">rdd2.keys.collect</span><br><span class="line">rdd2.values.collect</span><br></pre></td></tr></table></figure>
</div><div class="tags"><a href="/tags/Spark/">Spark</a></div><div class="post-nav"><a class="pre" href="/2018/08/15/SparkStreaming消费Kafka数据/">SparkStreaming消费Kafka数据</a><a class="next" href="/2018/08/15/Scala基本使用/">Scala基本使用-杂记</a></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form class="search-form" action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank"><input type="text" name="q" maxlength="20" placeholder="Search"/><input type="hidden" name="sitesearch" value="http://gangtieguo.cn"/></form></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Docker/">Docker</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Hexo/">Hexo</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Linux/">Linux</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Spark-On-Yarn/">Spark-On-Yarn</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Spring/">Spring</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/tool/">tool</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/博客/">博客</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/大数据/">大数据</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/安装部署/">安装部署</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/工程框架/">工程框架</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/快捷键/">快捷键</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/总结/">总结</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/框架/">框架</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/环境配置/">环境配置</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/碎片知识/">碎片知识</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/组件/">组件</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/语言/">语言</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/Mysql/" style="font-size: 15px;">Mysql</a> <a href="/tags/Jenkins/" style="font-size: 15px;">Jenkins</a> <a href="/tags/Ambari/" style="font-size: 15px;">Ambari</a> <a href="/tags/CDH/" style="font-size: 15px;">CDH</a> <a href="/tags/Docker-machine/" style="font-size: 15px;">Docker-machine</a> <a href="/tags/安装部署/" style="font-size: 15px;">安装部署</a> <a href="/tags/Hadoop/" style="font-size: 15px;">Hadoop</a> <a href="/tags/HBase/" style="font-size: 15px;">HBase</a> <a href="/tags/原理/" style="font-size: 15px;">原理</a> <a href="/tags/操作/" style="font-size: 15px;">操作</a> <a href="/tags/HDFS/" style="font-size: 15px;">HDFS</a> <a href="/tags/Shell/" style="font-size: 15px;">Shell</a> <a href="/tags/Hive/" style="font-size: 15px;">Hive</a> <a href="/tags/使用/" style="font-size: 15px;">使用</a> <a href="/tags/报表/" style="font-size: 15px;">报表</a> <a href="/tags/Json/" style="font-size: 15px;">Json</a> <a href="/tags/Scala/" style="font-size: 15px;">Scala</a> <a href="/tags/Kafka/" style="font-size: 15px;">Kafka</a> <a href="/tags/大数据/" style="font-size: 15px;">大数据</a> <a href="/tags/linux/" style="font-size: 15px;">linux</a> <a href="/tags/开发/" style="font-size: 15px;">开发</a> <a href="/tags/Linux/" style="font-size: 15px;">Linux</a> <a href="/tags/Docker/" style="font-size: 15px;">Docker</a> <a href="/tags/Spark/" style="font-size: 15px;">Spark</a> <a href="/tags/Yarn/" style="font-size: 15px;">Yarn</a> <a href="/tags/Java/" style="font-size: 15px;">Java</a> <a href="/tags/SSH/" style="font-size: 15px;">SSH</a> <a href="/tags/RDD/" style="font-size: 15px;">RDD</a> <a href="/tags/SparkStreaming/" style="font-size: 15px;">SparkStreaming</a> <a href="/tags/SparkSQL/" style="font-size: 15px;">SparkSQL</a> <a href="/tags/ELK/" style="font-size: 15px;">ELK</a> <a href="/tags/es/" style="font-size: 15px;">es</a> <a href="/tags/git/" style="font-size: 15px;">git</a> <a href="/tags/命令/" style="font-size: 15px;">命令</a> <a href="/tags/FLINK/" style="font-size: 15px;">FLINK</a> <a href="/tags/Hue/" style="font-size: 15px;">Hue</a> <a href="/tags/Hexo/" style="font-size: 15px;">Hexo</a> <a href="/tags/技术/" style="font-size: 15px;">技术</a> <a href="/tags/zk/" style="font-size: 15px;">zk</a> <a href="/tags/快捷键/" style="font-size: 15px;">快捷键</a> <a href="/tags/Mac/" style="font-size: 15px;">Mac</a> <a href="/tags/Idea/" style="font-size: 15px;">Idea</a> <a href="/tags/Finder/" style="font-size: 15px;">Finder</a> <a href="/tags/Other/" style="font-size: 15px;">Other</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2018/09/04/Spark-on-Yarn源码解析(四)Spark业务代码的执行及其任务分配调度stage划分/">Spark-on-Yarn源码解析(四)Spark业务代码的执行及其任务分配调度stage划分</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/09/04/Spark-on-Yarn源码解析(三)client做的事情/">Spark-on-Yarn源码解析(三)client做的事情</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/09/04/Spark-on-Yarn源码解析(二)Spark-Submit解析/">Spark-on-Yarn源码解析(二)Spark-Submit解析</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/09/04/Spark-on-Yarn源码解析(一)Yarn任务解析/">Spark-on-Yarn源码解析(一)Yarn任务解析</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/08/20/MapReduce中Shuffle中的机制/">MapReduce中Shuffle中的机制</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/08/16/SparkSQL介绍/">SparkSQL介绍</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/08/16/Spark-On-yarn/">Spark-On-Yarn模式</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/08/16/SparkStreaming介绍/">SparkStreaming介绍</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/08/16/SparkRDD介绍/">SparkRDD介绍</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/08/16/Hadoop零碎知识点/">Hadoop零碎知识点</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="http://www.example1.com/" title="site-name1" target="_blank">site-name1</a><ul></ul><a href="http://www.example2.com/" title="site-name2" target="_blank">site-name2</a><ul></ul><a href="http://www.example3.com/" title="site-name3" target="_blank">site-name3</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2018 <a href="/." rel="nofollow">钢铁锅.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/3.3.5/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/fancybox/3.3.5/jquery.fancybox.min.css"><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>